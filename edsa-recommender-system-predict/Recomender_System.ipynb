{
 "cells": [
  {
   "source": [
    "# Introduction "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting yellowbrick\n  Downloading yellowbrick-1.2-py3-none-any.whl (269 kB)\nRequirement already satisfied, skipping upgrade: numpy>=1.13.0 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from yellowbrick) (1.18.5)\nRequirement already satisfied, skipping upgrade: scipy>=1.0.0 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from yellowbrick) (1.4.1)\nRequirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.2 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from yellowbrick) (3.1.3)\nRequirement already satisfied, skipping upgrade: scikit-learn>=0.20 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from yellowbrick) (0.23.2)\nRequirement already satisfied, skipping upgrade: cycler>=0.10.0 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from yellowbrick) (0.10.0)\nRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.6)\nRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.1.0)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->yellowbrick) (0.14.1)\nRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->yellowbrick) (2.1.0)\nRequirement already satisfied, skipping upgrade: six in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from cycler>=0.10.0->yellowbrick) (1.14.0)\nRequirement already satisfied, skipping upgrade: setuptools in c:\\users\\zoemo\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (45.2.0.post20200210)\nInstalling collected packages: yellowbrick\nSuccessfully installed yellowbrick-1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U yellowbrick"
   ]
  },
  {
   "source": [
    "# Load the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from surprise.reader import Reader\n",
    "from surprise.dataset import Dataset\n",
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor\n",
    "from surprise import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "from surprise import BaselineOnly, CoClustering\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import scipy as sp \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import cufflinks as cf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import operator \n",
    "import heapq \n",
    "import xgboost as xgb\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBaseline\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "source": [
    "# Load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores = pd.read_csv('genome_scores.csv')\n",
    "genome_tags = pd.read_csv('genome_tags.csv')\n",
    "imdb = pd.read_csv('imdb_data.csv')\n",
    "links = pd.read_csv('links.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000038, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000038 entries, 0 to 10000037\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 305.2 MB\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000019, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000019 entries, 0 to 5000018\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Dtype\n",
      "---  ------   -----\n",
      " 0   userId   int64\n",
      " 1   movieId  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 76.3 MB\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title_cast</th>\n",
       "      <th>director</th>\n",
       "      <th>runtime</th>\n",
       "      <th>budget</th>\n",
       "      <th>plot_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wal...</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>81.0</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>toy|rivalry|cowboy|cgi animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Robin Williams|Jonathan Hyde|Kirsten Dunst|Bra...</td>\n",
       "      <td>Jonathan Hensleigh</td>\n",
       "      <td>104.0</td>\n",
       "      <td>$65,000,000</td>\n",
       "      <td>board game|adventurer|fight|game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Ma...</td>\n",
       "      <td>Mark Steven Johnson</td>\n",
       "      <td>101.0</td>\n",
       "      <td>$25,000,000</td>\n",
       "      <td>boat|lake|neighbor|rivalry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Whitney Houston|Angela Bassett|Loretta Devine|...</td>\n",
       "      <td>Terry McMillan</td>\n",
       "      <td>124.0</td>\n",
       "      <td>$16,000,000</td>\n",
       "      <td>black american|husband wife relationship|betra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Steve Martin|Diane Keaton|Martin Short|Kimberl...</td>\n",
       "      <td>Albert Hackett</td>\n",
       "      <td>106.0</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>fatherhood|doberman|dog|mansion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                         title_cast  \\\n",
       "0        1  Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wal...   \n",
       "1        2  Robin Williams|Jonathan Hyde|Kirsten Dunst|Bra...   \n",
       "2        3  Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Ma...   \n",
       "3        4  Whitney Houston|Angela Bassett|Loretta Devine|...   \n",
       "4        5  Steve Martin|Diane Keaton|Martin Short|Kimberl...   \n",
       "\n",
       "              director  runtime       budget  \\\n",
       "0        John Lasseter     81.0  $30,000,000   \n",
       "1   Jonathan Hensleigh    104.0  $65,000,000   \n",
       "2  Mark Steven Johnson    101.0  $25,000,000   \n",
       "3       Terry McMillan    124.0  $16,000,000   \n",
       "4       Albert Hackett    106.0  $30,000,000   \n",
       "\n",
       "                                       plot_keywords  \n",
       "0                   toy|rivalry|cowboy|cgi animation  \n",
       "1                   board game|adventurer|fight|game  \n",
       "2                         boat|lake|neighbor|rivalry  \n",
       "3  black american|husband wife relationship|betra...  \n",
       "4                    fatherhood|doberman|dog|mansion  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId   tmdbId\n",
       "0        1  114709    862.0\n",
       "1        2  113497   8844.0\n",
       "2        3  113228  15602.0\n",
       "3        4  114885  31357.0\n",
       "4        5  113041  11862.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>classic</td>\n",
       "      <td>1439472355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>1439472256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "      <td>dark comedy</td>\n",
       "      <td>1573943598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "      <td>great dialogue</td>\n",
       "      <td>1573943604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7569</td>\n",
       "      <td>so bad it's good</td>\n",
       "      <td>1573943455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId               tag   timestamp\n",
       "0       3      260           classic  1439472355\n",
       "1       3      260            sci-fi  1439472256\n",
       "2       4     1732       dark comedy  1573943598\n",
       "3       4     1732    great dialogue  1573943604\n",
       "4       4     7569  so bad it's good  1573943455"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  tagId  relevance\n",
       "0        1      1    0.02875\n",
       "1        1      2    0.02375\n",
       "2        1      3    0.06250\n",
       "3        1      4    0.07575\n",
       "4        1      5    0.14075"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =pd.merge(movies,imdb,how = 'left',on = 'movieId')\n",
    "genome_score_tags = pd.merge(genome_scores,genome_tags, how='left',on='tagId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metadata dataset has 62423 rows/entries and 8 coulumns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_cast</th>\n",
       "      <td>47222</td>\n",
       "      <td>75.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director</th>\n",
       "      <td>47076</td>\n",
       "      <td>75.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>48902</td>\n",
       "      <td>78.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget</th>\n",
       "      <td>55140</td>\n",
       "      <td>88.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot_keywords</th>\n",
       "      <td>48039</td>\n",
       "      <td>76.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count  Percentage\n",
       "movieId            0        0.00\n",
       "title              0        0.00\n",
       "genres             0        0.00\n",
       "title_cast     47222       75.65\n",
       "director       47076       75.41\n",
       "runtime        48902       78.34\n",
       "budget         55140       88.33\n",
       "plot_keywords  48039       76.96"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The metadata dataset has {metadata.shape[0]} rows/entries and {len(metadata.columns)} coulumns')\n",
    "percentange=metadata.isnull().mean().round(4) * 100\n",
    "count = metadata.isnull().sum()\n",
    "count_percentage = pd.DataFrame({'Count':count,'Percentage': percentange,},index=metadata.columns)\n",
    "count_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata1 = metadata.copy() \n",
    "\n",
    "metadata1.drop(['title_cast','director','budget','plot_keywords'],\n",
    "  axis='columns',inplace=True)\n",
    "\n",
    "metadata1['runtime'].fillna((metadata1['runtime'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(metadata1,genome_score_tags,how = 'left',on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting released year\n",
    "df['release_year']=df['title'].str[-5:-1] \n",
    "df['release_year'].replace('[^\\(.*\\)?]','', regex=True)\n",
    "#spliting the genres into a list\n",
    "df['genres']=df['genres'].str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_df dataset 23190655 rows/entries and 11 coulumns\n",
      "The test_df dataset 22765400 rows/entries and 9 coulumns\n"
     ]
    }
   ],
   "source": [
    "train_min = train[:10000]\n",
    "train_df =pd.merge(df,train_min,how = 'left',on = 'movieId')\n",
    "test_min = test[:10000]\n",
    "test_df = pd.merge(df,test_min,how = 'left',on = 'movieId')\n",
    "print(f'The train_df dataset {test_df.shape[0]} rows/entries and {len(train_df.columns)} coulumns')\n",
    "print(f'The test_df dataset {train_df.shape[0]} rows/entries and {len(test_df.columns)} coulumns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('timestamp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22765400, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = train_df.drop(['rating'],axis=1)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(smooth_idf=False, sublinear_tf=False, norm=None, analyzer='char')\n",
    "train_transformed = tf.fit_transform(train_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False)\n",
    "pca =PCA()\n",
    "pipeline = make_pipeline(scaler,pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.fit_transform(train_transformed)\n",
    "features=range(pca.n_components_)\n",
    "features = features\n",
    "plt.bar(features,pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False)\n",
    "scaled= scaler.fit_transform(train_transformed)\n",
    "wcss = []\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 10), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 3)\n",
    "y_kmeans = kmeans.fit_predict(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(scaled[y_kmeans == 0, 0],scaled[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
    "plt.scatter(scaled[y_kmeans == 1, 0], scaled[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
    "plt.scatter(scaled[y_kmeans == 2, 0], scaled[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "source": [
    "## Content-Based Filtering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In trying to achieve the ultimate user experience that keeps users coming back to use the product. The company needs to tailor the product to the user through a filtering process.A content-based recommender system strives to create the best user experience by tailoring the product to the user.This is done by using content based filtering methods,these methods utilise the desciption of the item and a profile of the user's preferences (basically the content).The method is efficient when there is known data on the item (such as the title,description,genre etc.) but it does not use the data on the user.With all that theory in mind, The Content-Based Filtering I am going to build a Content-Based Recommendation Engine that computes similarity between movies based on movie genres. It will suggest movies that are most similar to a particular movie based on its genre. The movies.csv dataset is used to build the recommender."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break up the big genre string into a string array\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "# Convert genres to string value\n",
    "movies['genres'] = movies['genres'].fillna(\"\").astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#create a sample of the movies genres  \n",
    "sample_genre= movies['genres'].head(20000)\n",
    "sample_genre.shape"
   ]
  },
  {
   "source": [
    "### Vectorizing the content "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The concepts of **Term Frequency (TF)** and **Inverse Document Frequency (IDF)** are used in information retrieval systems and also content based filtering mechanisms (such as a content based recommender). They are used to determine the relative importance of a document / article / news item / movie etc.\n",
    "\n",
    "TF is simply the frequency of a word in a document. IDF is the inverse of the document frequency among the whole corpus of documents. TF-IDF is used mainly because of two reasons: Suppose we search for “the results of latest European Socccer games” on Google. It is certain that “the” will occur more frequently than “soccer games” but the relative importance of soccer games is higher than the search query point of view. In such cases, TF-IDF weighting negates the effect of high frequency words in determining the importance of an item (document).\n",
    "\n",
    "Below is the equation to calculate the TF-IDF score:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a vectorizer\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "genre_vec = tf.fit_transform(sample_genre)"
   ]
  },
  {
   "source": [
    "### Finding the Similarities between movies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To find the similarities between two movies we made use of the **[Cosine Similarity](https://masongallo.github.io/machine/learning,/python/2016/07/29/cosine-similarity.html)** to calculate a numeric quantity that denotes the similarity between the two movies.We made use of sklearn's linear_kernel to generate the cosine similarities. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(genre_vec, genre_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_recommendations(movie_title):\n",
    "\n",
    "    \"Function that generates movie recommendations based on the cosine similarity score of movie genres \"\n",
    "    \"\n",
    " \n",
    "    # Build a 1-dimensional array with movie titles\n",
    "    movie_index=pd.Series(movies.index,index=movies['title'])\n",
    "    \n",
    "    #generate  similarities between the movie title and movie index based on genre\n",
    "    similarities=list(enumerate(cosine_sim[movie_index[movie_title]]))\n",
    "    #generate the top 10 similarities\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    recommended_movies= movies['title'].iloc[[i[0] for i in similarities]]\n",
    "    \n",
    "    return recommended_movies"
   ]
  },
  {
   "source": [
    "### Top 10 recommendations based on a movie title "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2203                                           Antz (1998)\n",
       "3021                                    Toy Story 2 (1999)\n",
       "3653        Adventures of Rocky and Bullwinkle, The (2000)\n",
       "3912                      Emperor's New Groove, The (2000)\n",
       "4780                                 Monsters, Inc. (2001)\n",
       "9949     DuckTales: The Movie - Treasure of the Lost La...\n",
       "10773                                     Wild, The (2006)\n",
       "11604                               Shrek the Third (2007)\n",
       "12969                       Tale of Despereaux, The (2008)\n",
       "17431    Asterix and the Vikings (Astérix et les Viking...\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "genre_recommendations('Toy Story (1995)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10                  American President, The (1995)\n",
       "51                         Mighty Aphrodite (1995)\n",
       "57               Postman, The (Postino, Il) (1994)\n",
       "92                          Beautiful Girls (1996)\n",
       "193                 Something to Talk About (1995)\n",
       "221                        Don Juan DeMarco (1995)\n",
       "229    Eat Drink Man Woman (Yin shi nan nu) (1994)\n",
       "278                           Nobody's Fool (1994)\n",
       "346                        Corrina, Corrina (1994)\n",
       "354                     I Like It Like That (1994)\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "genre_recommendations('Waiting to Exhale (1995)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "Collaborative Filtering is the most common technique used when it comes to building intelligent recommender systems that can learn to give better recommendations as more information about users is collected.\n",
    "\n",
    "Collaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users. It works by searching a large group of people and finding a smaller set of users with tastes similar to a particular user. It looks at the items they like and combines them to create a ranked list of suggestions.\n",
    "\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
    "\n",
    "***Surprise:***\n",
    "\n",
    "* Provides various ready-to-use prediction algorithms such as baseline algorithms, neighborhood methods, matrix factorization-based ( SVD, PMF, SVDpp, NMF), and many others.\n",
    "* Provides tools to evaluate, analyse and compare the algorithms’ performance.\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/getting_started.html http://surpriselib.com/#:~:text=Surprise%20is%20a%20Python%20scikit,perfect%20control%20over%20their%20experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Suprise library, the follwoing algorithms were used:\n",
    "\n",
    "# Basic algorithms\n",
    "***NormalPredictor:*** this algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "\n",
    "***BaselineOnly:*** this algorithm predicts the baseline estimate for given user and item.\n",
    "\n",
    "# k-NN algorithms\n",
    "***KNNBasic:*** this is a basic collaborative filtering algorithm.\n",
    "\n",
    "***KNNWithMeans:*** this is a basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "\n",
    "***KNNWithZScore:*** this is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "\n",
    "***KNNBaseline:*** is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "# Matrix Factorization-based algorithms\n",
    "***SVD:*** this algorithm is equivalent to Probabilistic Matrix Factorization ( which makes use of data provided by users with similar preferences to offer recommendations to a particular user).\n",
    "\n",
    "***SVDpp:*** this algorithm is an extension of SVD that takes into account implicit ratings.\n",
    "\n",
    "***NMF:*** this is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD.\n",
    "\n",
    "***SlopeOne:*** this is a straightforward implementation of the SlopeOne algorithm.\n",
    "\n",
    "***Coclustering:*** is a collaborative filtering algorithm based on co-clustering.\n",
    "\n",
    "https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Suprise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading 10000 dataset\n",
    "data = Dataset.load_from_df(train[['userId', 'movieId', 'rating']].head(10000), Reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Implement an algorithm\n",
    "algo = [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), \n",
    "                  KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]\n",
    "\n",
    "#Read 10000 dataset\n",
    "data2 = Dataset.load_from_df(train[['userId', 'movieId', 'rating']].head(10000), Reader())\n",
    "\n",
    "#Implementing algorithm for RMSE\n",
    "algo_rmse=[]\n",
    "for a in algo:\n",
    "    \n",
    "    cross_valid=cross_validate(a, data2, measures=['RMSE'], cv = 3)\n",
    "    output=pd.DataFrame.from_dict(cross_valid).mean(axis=0)\n",
    "    output=output.append(pd.Series([str(a).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    algo_rmse.append(output)\n",
    "\n",
    "algo_rmse\n",
    "surprise_results = pd.DataFrame(algo_rmse).set_index('Algorithm').sort_values('test_rmse')\n",
    "surprise_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the table above containing test_rmse, fit_time, test_time values for the algorithms, we notice that the SVDpp, SVD and BaselineOnly algorithms are top three best performing algorithms. So we use the best performing top three for prediction and to find the Root Mean Squared Error (RMSE) values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting with SVDpp algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading 100000 dataset\n",
    "data4 = Dataset.load_from_df(train[['userId', 'movieId', 'rating']].head(100000), Reader()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data4, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "#SVDpp model\n",
    "svdpp=SVDpp(n_epochs = 30, n_factors = 200, init_std_dev = 0.05, random_state=42)\n",
    "\n",
    "#Fitting the model\n",
    "svdpp.fit(trainset)\n",
    "\n",
    "# Making prediction on the validation dataset\n",
    "test_pred= svdpp.test(testset)\n",
    "\n",
    "#Evaluating model performance\n",
    "rsme_collabo = accuracy.rmse(test_pred,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the rating for each user and movie\n",
    "ratings=[]\n",
    "for x,y in test.itertuples(index=False):\n",
    "    output=svdpp.predict(x,y)\n",
    "    ratings.append(output)\n",
    "    \n",
    "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
    "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
    "output_df=output_df[['ID','est']]\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the \"results\" dataframe and convert to csv\n",
    "results = pd.DataFrame({\"Id\":output_df['ID'],\"rating\": output_df['est']})\n",
    "results.to_csv(\"SVDpp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting with BaselineOnly algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading 1100000 dataset\n",
    "data5 = Dataset.load_from_df(train[['userId', 'movieId', 'rating']].head(1100000), Reader()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data5, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "#BaselineOnly model\n",
    "bsl_options = {'method': 'sgd','n_epochs': 40}\n",
    "blo=BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "#Fitting the model\n",
    "blo.fit(trainset)\n",
    "\n",
    "# Making prediction on the validation dataset\n",
    "test_pred= blo.test(testset)\n",
    "\n",
    "#Evaluating model performance\n",
    "rsme_collabo = accuracy.rmse(test_pred,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the rating for each user and movie\n",
    "ratings=[]\n",
    "for x,y in test.itertuples(index=False):\n",
    "    output=blo.predict(x,y)\n",
    "    ratings.append(output)\n",
    "    \n",
    "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
    "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
    "output_df=output_df[['ID','est']]\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the \"results\" dataframe and convert to csv\n",
    "results = pd.DataFrame({\"Id\":output_df['ID'],\"rating\": output_df['est']})\n",
    "results.to_csv(\"blo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading 1000000 dataset\n",
    "data3 = Dataset.load_from_df(train[['userId', 'movieId', 'rating']].head(1000000), Reader()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data3, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "#SVD model\n",
    "svd=SVD(n_epochs = 30, n_factors = 200, init_std_dev = 0.05, random_state=42)\n",
    "\n",
    "#Fitting the model\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Making prediction on the validation dataset\n",
    "test_pred= svd.test(testset)\n",
    "\n",
    "#Evaluating model performance\n",
    "rsme_collabo = accuracy.rmse(test_pred,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the rating for each user and movie\n",
    "ratings=[]\n",
    "for x,y in test.itertuples(index=False):\n",
    "    output=svd.predict(x,y)\n",
    "    ratings.append(output)\n",
    "    \n",
    "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
    "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
    "output_df=output_df[['ID','est']]\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the \"results\" dataframe and convert to csv\n",
    "results = pd.DataFrame({\"Id\":output_df['ID'],\"rating\": output_df['est']})\n",
    "results.to_csv(\"SVD.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is the process of determining the right combination of hyperparameters that allows the model to maximize model performance. Setting the correct combination of hyperparameters is the only way to extract the maximum performance out of models.\n",
    "\n",
    "We decided to hypertune the SVD algorithm model, which was the best performing amongst the top three algorithm (since it had the lowest RMSE value).\n",
    "\n",
    "https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs':[40], #[30,40,50],\n",
    "              'n_factors':[400], #[100,200,300,400],\n",
    "              'init_std_dev':[0.005], #[0.001,0.005,0.05,0.1],\n",
    "              'random_state':[42]} \n",
    "grid_SVD = GridSearchCV(SVD, cv=5, measures=['rmse'], param_grid=param_grid, n_jobs=-1)\n",
    "grid_SVD.fit(data3)\n",
    "print('***Best score:***')\n",
    "print(grid_SVD.best_score['rmse'])\n",
    "print('***Best parameters:***')\n",
    "print(grid_SVD.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Conclusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}